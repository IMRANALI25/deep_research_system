from agents import (
    Agent,
    Runner,
    handoff,
    OpenAIChatCompletionsModel,
    ModelSettings,
    set_tracing_disabled,
    function_tool,
    RunContextWrapper,
    ItemHelpers,
)
from openai import (
    OpenAIError,
    BadRequestError,
    AuthenticationError,
    APIConnectionError,
    APIStatusError,
    APIError,
    AsyncOpenAI,
    RateLimitError,
    PermissionDeniedError,
    NotFoundError,
    InternalServerError,
)
from utilities import (
    api_keys as AK,
    helper_functions as HF,
    llm_parameters as LP,
    config_constants as CC,
    user_profile as UP,
    helper_classes as HC,
    topics,
)

import datetime, time, sys, os
import random
from typing import Union, List, Dict
import json

# DELAYED TYPING PARAMETERS
def delayed_print(
    text: Union[str, List[str]] | None,
    delay: float = 0.00006,
    char_by_char: bool = True,
    line_delay: float = None,
):
    """
    Print text (or multiple lines) with delays.

    Args:
        text (str | list[str]): Single string or list of strings to print.
        delay (float): Base delay in seconds.
                       If char_by_char=True â†’ delay per character.
                       If char_by_char=False â†’ delay after each print.
        char_by_char (bool): If True, prints like typing effect.
        line_delay (float): Extra delay between lines (if list is passed).
                            Defaults to delay if not provided.
    """
    if isinstance(text, str):
        lines = [text]
    else:
        lines = text

    for line in lines:
        if char_by_char:
            for char in line:
                print(char, end="", flush=True)
                time.sleep(delay)
            print()  # move to next line
        else:
            print(line, flush=True)

        # Delay after each line
        time.sleep(line_delay if line_delay is not None else delay)


# ğŸ¤ INITIALIZE USER FOR LOCAL CONTEXT OBJECT
def get_user_profile():
    return UP.UserContext()


def get_deep_research_topic() -> str:
    try:
        delayed_print("\nğŸ™‹ Enter the Research Topic. [Press ğ’’ to quit ğŸšªğŸƒ]:}")
        CC.RESEARCH_TOPIC = input()

        if not CC.RESEARCH_TOPIC:
            delayed_print(
                "ğŸ–Šï¸ No research topic is provided.\nğŸ•µï¸â€â™‚ï¸ Agent will choose any one of tht topic from below mentioned list..."
            )

            for i, topic in enumerate(topics.DEEP_RESEARCH_TOPICS, start=1):
                delayed_print(f"{i:>03}. ğŸ“‘ {topic}")

            topic_index = random.randint(0, len(topics.DEEP_RESEARCH_TOPICS) - 1)
            CC.RESEARCH_TOPIC = topics.DEEP_RESEARCH_TOPICS[topic_index]
            # pass
        elif CC.RESEARCH_TOPIC == "q":
            delayed_print("ğŸ•µï¸â€â™‚ï¸ Agent is exiting from deep research task...")
            exit(0)

        delayed_print(f"\n ğŸ¢ƒ Deep ğŸ”¬ Research ğŸ“‘ Topic ğŸ“‹ â¢â¢â¤â¤ {CC.RESEARCH_TOPIC}")
        return CC.RESEARCH_TOPIC
    except Exception as e:
        print(f"âŒ [ ERROR - helper_functions.py - get_deep_research_topic()] {type(e).__name__}: {e}")
        exit(1)


def get_file_path(research_topic: str, file_format: HC.FileFormat):
    # Get current date & time
    try:
        timestamp = datetime.datetime.now().strftime("%Y-%m-%d_%H-%M-%S")
        # Define folder path
        folder = "C:/Research_Reports"  # Windows style
        # Create folder if it doesnâ€™t exist
        os.makedirs(folder, exist_ok=True)

        report_name = (research_topic)[0:80]
        # Replace special characters
        for ch in ["?", ":", "/", "*", "<", ">", "|", '"', "\\", " "]:
            report_name = report_name.replace(ch, "_")

        # Build md filename
        report_name = f"{report_name}_{timestamp}.{file_format.value.lower()}"

        file_path = os.path.join(folder, report_name)
        return report_name, file_path
    except Exception as e:
        print(f"âŒ [ERROR helper_functions.py -  get_file_path()] {type(e).__name__}: {e}")
        exit(1)

# @function_tool
def get_md_report(final_output, research_topic):
    try:
        report_name, file_path = get_file_path(research_topic, HC.FileFormat.MD)

        md_content = f"# {research_topic} \n\n"

        if isinstance(final_output, dict):
            for key, value in final_output.items():
                md_content += f"## {key}\n"
                if isinstance(value, (dict, list)):
                    md_content += f"```json\n{json.dumps(value, indent=2)}\n```\n\n"
                else:
                    md_content += f"{value}\n\n"
        elif isinstance(final_output, list):
            md_content += "## Items\n"
            for idx, item in enumerate(final_output, 1):
                md_content += f"- **Item {idx}:** {item}\n"
        else:
            md_content += str(final_output)

        # return md_content 
        with open(file_path, "w", encoding="utf-8") as f:
            f.write(md_content)

        delayed_print(
            f"ğŸ“˜ Research Report in ğŸ“‘ MarkDown format is saved ğŸ“€ as {report_name}",
        )

        delayed_print(
            f"ğŸ—‚ï¸ File Path: ğŸ“‚ {file_path}",
        )

        delayed_print("ğŸ”" * 60)
        delayed_print(
            f"""\nâ®â®â®â®â®  ğŸ“œâœï¸  The Final Report for
ğŸ“° {research_topic[0:100]}
âœ’ï¸  Generated Successfully  ğŸ’¯ğŸ†ğŸ¯ and Saved ğŸ“€
to ğŸ“‚ {file_path}   â®œâ®œâ®œâ®œâ®œ \n""")
        delayed_print("ğŸ”" * 60,)

    except PermissionError as e:
        print(
            f"âŒ Error: You donâ€™t have permission to write to {report_name}. {e}"
        )
        exit(1)
    except Exception as e:
        print(f"âŒ [ERROR helper_functions.py - get_md_report()] {type(e).__name__}: {e}")
        exit(1)


# @function_tool
def get_html_report(final_output, research_topic):
    try:
        report_name, file_path = get_file_path(research_topic, HC.FileFormat.HTML)
        start_marker = "<!DOCTYPE html>"
        end_marker = "</html>"

        # Find starting index
        start_index = final_output.find(start_marker)
        if start_index == -1:
            return "Error: <!DOCTYPE html> not found."

        # Find ending index
        end_index = final_output.find(end_marker, start_index)
        if end_index == -1:
            return "Error: </html> not found."

        # Include the </html> tag in output
        end_index += len(end_marker)

        delayed_print("ğŸ•µï¸â€â™‚ï¸ Agent is generating HTML document...")

        html_output = final_output[start_index:end_index]
        # PRINT ONLY HTML
        # print(html_output)

        if html_output.startswith("Error:"):
            print(html_output)  # If error message, just print it
            return
                
        delayed_print(
            f"\nğŸŒ Creating ğŸ‘‰ HTML Formatted Report for ğŸ“œ {research_topic}\n",
        )

        with open(file_path, "w", encoding="utf-8") as f:
            f.write(html_output)

        delayed_print(
            f"ğŸ“˜ Research Report in ğŸŒ HTML format is saved ğŸ“€ as {report_name}",
        )

        delayed_print(
            f"ğŸ—‚ï¸ File Path: ğŸ“‚ {file_path}",
        )

        delayed_print("ğŸ”" * 60)
        delayed_print(
            f"""\nâ®â®â®â®â®  ğŸ“œâœï¸  The Final Report for
ğŸ“° {research_topic[0:100]}
âœ’ï¸  Generated Successfully  ğŸ’¯ğŸ†ğŸ¯ and Saved ğŸ“€
to ğŸ“‚ {file_path}   â®œâ®œâ®œâ®œâ®œ \n""")
        delayed_print("ğŸ”" * 60)

    except PermissionError as e:
        print(
            f"âŒ Error: You donâ€™t have permission to write to '{html_format_report}'. {e}"
        )
        exit(1)
    except Exception as e:
        print(f"âŒ [ ERROR helper_functions.py - get_html_report()] {type(e).__name__}: {e}")
        exit(1)


def set_console_header(ctx_user_name: str, research_topic: str):
    print("\n")
    delayed_print("ğŸŸ§" * 50)
    delayed_print(
        f"ğŸ¤µ  User {ctx_user_name} \n",
    )

    delayed_print(
        f"ğŸŸ§" * 50,
    )
    print("\n")

    delayed_print(
        f"""ğŸ•µï¸â€â™‚ï¸  Agent Starting the Deep Research Process ğŸ”‚â¤â¤â¤â¤â¤\n""",
    )

    delayed_print(
        f"""ğŸ“• Deep Research Topic  â®â®â®â®â® ğŸ“œ {research_topic}    â®œâ®œâ®œâ®œâ®œ \n""",
    )
    delayed_print("ğŸŒ" * 50)
    print("\n")

    delayed_print("â­" * 50)
    print("\n")

    delayed_print(
        """ğŸ•µï¸â€â™‚ï¸ğŸ•µï¸â€â™‚ï¸  AI Agents are  ğŸ¤”ğŸ’­ Thinking, ğŸ” Searching, ğŸ”¬ Analyzing, 
        ğŸ»ğŸºğŸ· Synthesizing and finalizing âœ’ï¸ the Research Report ğŸ“Š.""",
    )
    delayed_print(
        "ğŸ•¸ï¸ Searching the WEB.......ğŸ•¸ï¸",
    )

    # delayed_print(
    #     "â³â³â³  Please Wait... â³â³â³",
    # )

    delayed_print("â­" * 50)

    print("\n")
    delayed_print("ğŸ“Œ" * 50)

    delayed_print(
        f"""        ğŸ› ï¸  Final Report ğŸ‘‰ For ğŸ“œ [{research_topic}]
                    ğŸ’¡  is Generating â¤â¤â¤ NOW...ğŸ’¡""",
    )
    delayed_print("ğŸ“Œ" * 50)
    print("\n")


def transform_response_data(response):
    emojis_header_bar("â­", number_of_emojis=50)

    print(f"\nğŸ” Query: {response['query']}\n")
    print(f"\nâœ… Answer: {response['answer']}\n")

    for i, result in enumerate(response["results"], start=1):
        # console.print(
        #     f"{i}. {result['title']}", style="bold red on yellow", justify="center"
        # )
        print(f"{i}. {result['title']}")
        print(f"   ğŸ“Œ URL: {result['url']}")
        # CONST.LIST_OF_URLS.append({result["url"]})
        print(f"   ğŸ“ Content: {result['content']}")
        # print(f"   ğŸ“Š Raw Data: {result['raw_content']}")

    print(f"   â³ Response Time: {response['response_time']}")

    emojis_header_bar("â­", number_of_emojis=40)


def get_llm_client_model():
    try:
        # âš™ï¸ INITIALIZE LLM SERVICE CLIENT
        LP.LLM_ASYNC_CLIENT: AsyncOpenAI = AsyncOpenAI(
            api_key=LP.GEMINI_API_KEY,
            base_url=LP.GEMINI_BASE_URL,
        )

        # ğŸ² INITIALIZE LLM MODEL USING CHAT COMPLETIONS MODEL
        LP.LLM_MODEL: OpenAIChatCompletionsModel = OpenAIChatCompletionsModel(
            model=LP.SELECTED_MODEL, openai_client=LP.LLM_ASYNC_CLIENT
        )
    except AuthenticationError as e:
        print(f"âŒ [AUTH ERROR] Invalid or missing API key: {e}")
        exit(1)
    except PermissionDeniedError as e:
        print(f"âŒ [PERMISSION ERROR] Access denied: {e}")
        exit(1)
    except RateLimitError as e:
        print(f" âŒ[RATE LIMIT ERROR] Too many requests: {e}")
        exit(1)
    except NotFoundError as e:
        print(f" âŒ[NOT FOUND ERROR] Resource missing: {e}")
        exit(1)
    except BadRequestError as e:
        print(f"âŒ [BAD REQUEST ERROR] Invalid parameters: {e}")
        exit(1)
    except APIConnectionError as e:
        print(f"âŒ [CONNECTION ERROR] Network problem: {e}")
        exit(1)
    except APIStatusError as e:
        print(f"âŒ [API STATUS ERROR] HTTP {e.status_code}: {e.response}")
        exit(1)
    except OpenAIError as e:
        print(f"âŒ[OPENAI ERROR] Unexpected client error: {e}")
        exit(1)
    except ImportError as e:
        print(f"âŒ [Import ERROR] Cannot Import File: {e}")
        exit(1)
    except Exception as e:
        print(f"âŒ [ERROR - helper_functions.py - get_llm_client_model() ] {type(e).__name__}: {e}")
        exit(1)


def get_runner_input(selected_agent_name: str, research_topic: str) -> str:
    INPUT_TO_RUNNER = ""
    try:
        match selected_agent_name:
            
            case "solo_agent":
                INPUT_TO_RUNNER = f"""You are the Expert Deep Research Assistant. 
                    Generate a deep research report of {research_topic}. 
                    You always perform deep research according to the given topic {research_topic}.                                        
                    You must gathered all requirements from web searching.
                    You must create a summarized technical query, do web searching,
                    synthesize, verify and validate the findings sources. 
                    """
            case "tavily_client_agent":
                INPUT_TO_RUNNER = f"""You are the Expert Deep Research Assistant. 
                    Generate a deep research report of {research_topic}. 
                    You always perform deep research according to the given topic {research_topic}.                    
                    Always use Tavily Web Services to gathering all requirements for web searching.
                    You must create a summarized technical query, do web searching,
                    synthesize, verify and validate the findings sources. 
                    """
                    
        return INPUT_TO_RUNNER
    except Exception as e:
        print(f"âŒ [ERROR - helper_functions.py - get_runner_input()] {type(e).__name__}: {e}")
        exit(1)
        
        
def pretty_print(obj, indent=0):
    """Recursively pretty-print dicts/lists from JSON objects."""
    spacing = "  " * indent
    if isinstance(obj, dict):
        for key, value in obj.items():
            print(f"{spacing}{key}:")
            pretty_print(value, indent + 1)
    elif isinstance(obj, list):
        for i, item in enumerate(obj):
            print(f"{spacing}- [{i}]")
            pretty_print(item, indent + 1)
    else:
        print(f"{spacing}{obj}")


def emojis_header_bar(emoji: str = "ğŸŸ ", number_of_emojis: int = 30):
    print(f"{emoji}" * number_of_emojis)


def emojis_header_bar_with_Info(
    message: str,
    emoji: str = "ğŸŸ ",
    start_number_of_emojis: int = 15,
    end_number_of_emojis: int = 15,
):
    print(f"{emoji * start_number_of_emojis} {message} {emoji * end_number_of_emojis}")


###################################################################################
# Extract JSON Dict from final Output


# def extract_data_from_response():
#     try:
#         parts = result.final_output.split("```")
#         print(parts)

#         for i, part in enumerate(parts):
#             if part.strip().startswith("json"):
#                 # Remove 'json' and keep the actual JSON content
#                 json_str = part.replace("json", "", 1).strip()
#                 # return json.loads(json_str)

#         print("ğŸ“Œ" * 50)
#         print(json_str)

#         with open("electric_car_benefits.json", "w", encoding="utf-8") as f:
#             json.dump(json_str, f, indent=4, ensure_ascii=False)

#         print("âœ… JSON extracted and saved as 'electric_car_benefits.json'")
#         print(json.dumps(json_str, indent=2, ensure_ascii=False))

#     except json.JSONDecodeError as e:
#         print("Error parsing JSON:", e)
#         exit(1)

###################################################################################

################################################################################
# SPECIAL PROMPT
# async def special_prompt(
#     special_context: RunContextWrapper[UserContext], agent: Agent[UserContext]
# ) -> str:

#     return f"""{CONST.SPECIAL_INSTRUCTIONS}\n You should use report and summary tools.
#                 Always save the report to context and handoff to Lead Agent.
#                 User: {special_context.context.user_name},
#                 Agent: {agent.name}"""


# Dynamic Instructions
# def dynamic_instructions(
#     local_context: RunContextWrapper[UserContext], agent: Agent[UserContext]
# ) -> str:
#     # Access conversation messages
#     messages = getattr(local_context, "messages", [])
#     message_count = len(messages)

#     return f"""You are {agent.name} with {len(agent.tools)} tools.
#                 You are an experienced assistant that can do research
#                 in any field of science and technology.
#                 You are facilitating deep research services to,
#                 {local_context.context.user_name}
#                 has preferences including {local_context.context.user_preferences}.
#                 The local time is {datetime.datetime.now().strftime("%m/%d/%Y %I:%M:%S %p")},
#                 This is the message #{message_count} in our conversation.
#                 Be helpful and informative!"""
################################################################################
